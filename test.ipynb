{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSetInitialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.utils import init_logger, init_seed\n",
    "from mamba4poi import Mamba4POI\n",
    "from recbole.config import Config\n",
    "from utils import *\n",
    "from recbole.data.transform import construct_transform\n",
    "from recbole.utils import (\n",
    "    init_logger,\n",
    "    get_model,\n",
    "    get_trainer,\n",
    "    init_seed,\n",
    "    set_color,\n",
    "    get_flops,\n",
    "    get_environment,\n",
    ")\n",
    "import torch\n",
    "from myutils import * \n",
    "\n",
    "config = Config(model=Mamba4POI, config_file_list=['config.yaml'])\n",
    "dataset = create_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data,test_data = data_preparation(config, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_user=(dataset.inter_feat[dataset.uid_field].max()+1).astype(int)\n",
    "num_category=(dataset.item_feat[\"venue_category_id\"].max()+1).astype(int)\n",
    "num_POI=(dataset.item_feat[\"venue_id\"].max()+1).astype(int)\n",
    "\n",
    "Ms=torch.zeros((num_user,num_category),dtype=torch.float32)\n",
    "_,M0,_,_=counting4all(train_data._dataset,device)\n",
    "\n",
    "Ec=torch.zeros((num_category,k),dtype=torch.float32)\n",
    "ESu=torch.zeros((num_user,k),dtype=torch.float32)\n",
    "\n",
    "itemX=(dataset.item_feat[\"longitude\"]).to_numpy()\n",
    "itemY=(dataset.item_feat[\"latitude\"]).to_numpy()\n",
    "itemC=(dataset.item_feat[\"venue_category_id\"]).to_numpy()\n",
    "Locations=torch.tensor(np.stack((itemX,itemY),axis=-1),dtype=torch.double)\n",
    "\n",
    "\n",
    "row_nonzero_mask=M0.sum(1)>0\n",
    "col_nonzero_mask=M0.sum(0)>0\n",
    "nonzero_M0=M0[row_nonzero_mask][:,col_nonzero_mask]\n",
    "\n",
    "E0u,S0,E0c=UC_SVD(nonzero_M0,k)\n",
    "\n",
    "Ec[col_nonzero_mask]=E0c\n",
    "\n",
    "EPOI=torch.einsum('ij,ik->ijk',Ec[itemC],Locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_data:\n",
    "    userids,item_seqs,Xs,Ys,Cs,labels,times,negs=batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Ms=accumulate_category(Cs,userids,Ms)\n",
    "s_row_nonzero_mask=Ms.sum(1)>0\n",
    "s_col_nonzero_mask=Ms.sum(0)>0\n",
    "nonzero_Ms=Ms[s_row_nonzero_mask][:,s_col_nonzero_mask]\n",
    "\n",
    "row,col=nonzero_Ms.shape\n",
    "size = max(row, col)  \n",
    "expanded_Ms = torch.zeros(size, size)\n",
    "expanded_Ms[:row,:col]=nonzero_Ms\n",
    "if row==size:\n",
    "    expanded_Ms[:,col:]=torch.eye(row,row - col) * 1e5\n",
    "else:\n",
    "    expanded_Ms[row:,:]=torch.eye(col-row,col)*1e5\n",
    "\n",
    "Esu,Ss,Esc=UC_SVD(expanded_Ms,k)\n",
    "\n",
    "Estu=Ec[s_col_nonzero_mask]@Esc.T@Esu\n",
    "ESu[s_row_nonzero_mask]=Estu[:row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=np.stack((Xs,Ys),axis=-1)\n",
    "El=torch.tensor(location,dtype=torch.double)\n",
    "Ep=torch.einsum('usj,usk->usjk',Ec[Cs],El)#numuserXnumseqXcategoryfeatureXLocationfeature\n",
    "S=torch.einsum('ut,usjk->ustjk',ESu[userids[:,0]],Ep)#numuserXnumseqXcategoryfeatureXLocationfeatureXUserFeat\n",
    "labels=torch.tensor(np.array(labels))\n",
    "valid_S=S[(labels==1)|(labels==2)].reshape(S.shape[0],-1,S.shape[2],S.shape[3],S.shape[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Times=torch.tensor(times,dtype=torch.double)\n",
    "dT=(Times[:,1:]-Times[:,:-1]).unsqueeze(2).unsqueeze(2).unsqueeze(2)\n",
    "S1=valid_S[:,1:]/dT\n",
    "S2=valid_S[:,:-1]/dT\n",
    "\n",
    "shape = S1.shape\n",
    "\n",
    "new_shape = (shape[0], shape[1] * 2, shape[2], shape[3], shape[4])\n",
    "\n",
    "Ss = torch.zeros(new_shape,dtype=torch.double)\n",
    "Ss[:,0::2]=S2\n",
    "Ss[:,1::2]=S1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "for obj in gc.get_objects():\n",
    "    if torch.is_tensor(obj) and obj.is_cuda:\n",
    "        print(type(obj), obj.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperGraphModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### notes:\n",
    "We use a **HyperGraph Neural Network** to model the complex interactions among users, categories, and POIs, calculating the weight of hyperedges to reflect users' **interests in both categories and POIs**.<br>\n",
    "Unlike our sequential prediction model, which predict user interest in the dynamic time sequence, the HGNN addresses the issue of dissimilar interests in the same POI caused by users' varied **breadth of interests** despite having equal interaction levels,by modeling static user profiles.The **distinction** between the two modules is determined by their approach to **utilizing interactions**: ***dynamically or statically***<br>\n",
    "#### Nodes defination:\n",
    "We detatch category from POI features to modeling its latent<br> relation between both POI and user<br><br>\n",
    "**User**:       10dims for 3 features<br>\n",
    "*num_poi_interaction*:int,*num_category_interaction*:int<br>\n",
    "***active_area:tensor***(4,2) <--training target<br><br>\n",
    "**Category**:   1dim for 1 feature<br>\n",
    "*num_poi*:int,sigma:float(2,),center:float(2,)<br>\n",
    "***using poi geographic distribution feature to reflect the feature of category***<br>\n",
    "<br><br>\n",
    "**POI**:        2dims for 1feature<br>\n",
    "*location*:tensor(2,)<br>\n",
    "\n",
    "             \n",
    "\n",
    "#### Weight updating policy:\n",
    "Our Hyperedge connected with three varied type nodes,whose weight can't be fully normalized as scalar,are designed with vector weight.Using attention mechanism to reflect the diffrent impact from nodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "_,M0,category_ids_counts,_=counting4all(dataset,device)\n",
    "row_nonzero_mask=M0.sum(1)>0\n",
    "col_nonzero_mask=M0.sum(0)>0\n",
    "Eu,S0,Ec=UC_SVD(M0[row_nonzero_mask][:,col_nonzero_mask],200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 假设原始矩阵 M0 和通过 SVD 得到的分解结果 U, Sigma, Ec\n",
    "# U, S0, Ec = UC_SVD(M0[row_nonzero_mask][:, col_nonzero_mask], 200)\n",
    "M_reconstructed = np.dot(Eu, np.dot(S0, Ec.T))  # 重建矩阵\n",
    "mse = np.mean((M0[row_nonzero_mask][:,col_nonzero_mask] - M_reconstructed) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Reconstruction MSE: {mse}')\n",
    "print(f'Reconstruction RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "def CreateAdjacencyList(locations):\n",
    "    radius=200\n",
    "    POI_tree=KDTree(locations)\n",
    "    query_point=locations[100]\n",
    "    adjacency_list = POI_tree.query_ball_point(locations,r=radius,p=1)\n",
    "    return adjacency_list\n",
    "locations=np.stack((itemX,itemY),axis=-1)\n",
    "adjacency_list=CreateAdjacencyList(locations)\n",
    "POI_ec=Ec[itemC]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jec\\AppData\\Local\\Temp\\ipykernel_7304\\3190118431.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  locations = torch.tensor(locations, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2299.855712890625\n",
      "Epoch 10, Loss: 2195.0791015625\n",
      "Epoch 20, Loss: 2094.681884765625\n",
      "Epoch 30, Loss: 1998.961181640625\n",
      "Epoch 40, Loss: 1907.9940185546875\n",
      "Epoch 50, Loss: 1821.69580078125\n",
      "Epoch 60, Loss: 1739.884521484375\n",
      "Epoch 70, Loss: 1662.33447265625\n",
      "Epoch 80, Loss: 1588.810302734375\n",
      "Epoch 90, Loss: 1519.0775146484375\n",
      "Epoch 100, Loss: 1452.916015625\n",
      "Epoch 110, Loss: 1390.1142578125\n",
      "Epoch 120, Loss: 1330.4771728515625\n",
      "Epoch 130, Loss: 1273.821044921875\n",
      "Epoch 140, Loss: 1219.9725341796875\n",
      "Epoch 150, Loss: 1168.7705078125\n",
      "Epoch 160, Loss: 1120.0650634765625\n",
      "Epoch 170, Loss: 1073.7147216796875\n",
      "Epoch 180, Loss: 1029.586669921875\n",
      "Epoch 190, Loss: 987.5582275390625\n",
      "Epoch 200, Loss: 947.5123291015625\n",
      "Epoch 210, Loss: 910.343505859375\n",
      "Epoch 220, Loss: 875.0350341796875\n",
      "Epoch 230, Loss: 841.5624389648438\n",
      "Epoch 240, Loss: 809.6142578125\n",
      "Epoch 250, Loss: 779.0738525390625\n",
      "Epoch 260, Loss: 749.8619995117188\n",
      "Epoch 270, Loss: 721.912109375\n",
      "Epoch 280, Loss: 695.1607666015625\n",
      "Epoch 290, Loss: 669.5487060546875\n",
      "Epoch 300, Loss: 645.0193481445312\n",
      "Epoch 310, Loss: 621.519287109375\n",
      "Epoch 320, Loss: 598.9978637695312\n",
      "Epoch 330, Loss: 577.4075317382812\n",
      "Epoch 340, Loss: 556.703857421875\n",
      "Epoch 350, Loss: 536.843505859375\n",
      "Epoch 360, Loss: 517.78662109375\n",
      "Epoch 370, Loss: 499.49554443359375\n",
      "Epoch 380, Loss: 481.9337158203125\n",
      "Epoch 390, Loss: 465.0673828125\n",
      "Epoch 400, Loss: 448.8643798828125\n",
      "Epoch 410, Loss: 433.29412841796875\n",
      "Epoch 420, Loss: 418.3276062011719\n",
      "Epoch 430, Loss: 403.9380187988281\n",
      "Epoch 440, Loss: 390.09893798828125\n",
      "Epoch 450, Loss: 376.785888671875\n",
      "Epoch 460, Loss: 363.97540283203125\n",
      "Epoch 470, Loss: 351.6456298828125\n",
      "Epoch 480, Loss: 339.77557373046875\n",
      "Epoch 490, Loss: 329.18878173828125\n",
      "Epoch 500, Loss: 318.685302734375\n",
      "Epoch 510, Loss: 308.6150817871094\n",
      "Epoch 520, Loss: 298.90545654296875\n",
      "Epoch 530, Loss: 289.55682373046875\n",
      "Epoch 540, Loss: 280.5377502441406\n",
      "Epoch 550, Loss: 271.8195495605469\n",
      "Epoch 560, Loss: 263.40277099609375\n",
      "Epoch 570, Loss: 255.26422119140625\n",
      "Epoch 580, Loss: 248.0723876953125\n",
      "Epoch 590, Loss: 240.89060974121094\n",
      "Epoch 600, Loss: 233.97238159179688\n",
      "Epoch 610, Loss: 227.29556274414062\n",
      "Epoch 620, Loss: 220.85430908203125\n",
      "Epoch 630, Loss: 214.5840606689453\n",
      "Epoch 640, Loss: 208.53672790527344\n",
      "Epoch 650, Loss: 202.65383911132812\n",
      "Epoch 660, Loss: 196.97573852539062\n",
      "Epoch 670, Loss: 191.44677734375\n",
      "Epoch 680, Loss: 186.090087890625\n",
      "Epoch 690, Loss: 180.8973388671875\n",
      "Epoch 700, Loss: 175.86190795898438\n",
      "Epoch 710, Loss: 170.97132873535156\n",
      "Epoch 720, Loss: 166.22726440429688\n",
      "Epoch 730, Loss: 161.63031005859375\n",
      "Epoch 740, Loss: 157.15631103515625\n",
      "Epoch 750, Loss: 152.82791137695312\n",
      "Epoch 760, Loss: 148.61203002929688\n",
      "Epoch 770, Loss: 144.51596069335938\n",
      "Epoch 780, Loss: 140.54696655273438\n",
      "Epoch 790, Loss: 136.6868438720703\n",
      "Epoch 800, Loss: 132.94027709960938\n",
      "Epoch 810, Loss: 129.3026123046875\n",
      "Epoch 820, Loss: 125.76072692871094\n",
      "Epoch 830, Loss: 122.31976318359375\n",
      "Epoch 840, Loss: 118.97320556640625\n",
      "Epoch 850, Loss: 115.72515869140625\n",
      "Epoch 860, Loss: 112.56786346435547\n",
      "Epoch 870, Loss: 109.4940185546875\n",
      "Epoch 880, Loss: 106.50627899169922\n",
      "Epoch 890, Loss: 103.60664367675781\n",
      "Epoch 900, Loss: 101.09375\n",
      "Epoch 910, Loss: 98.56768798828125\n",
      "Epoch 920, Loss: 96.12466430664062\n",
      "Epoch 930, Loss: 93.76184844970703\n",
      "Epoch 940, Loss: 91.44922637939453\n",
      "Epoch 950, Loss: 89.20358276367188\n",
      "Epoch 960, Loss: 87.00436401367188\n",
      "Epoch 970, Loss: 84.86424255371094\n",
      "Epoch 980, Loss: 82.78025817871094\n",
      "Epoch 990, Loss: 80.7509994506836\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class ProjectionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ProjectionModel, self).__init__()\n",
    "        self.projection_matrix = nn.Parameter(torch.randn(input_dim, output_dim))  # 可训练的投影矩阵\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.projection_matrix)  # 投影到高维空间\n",
    "\n",
    "def norm1_constraint(projection_matrix):\n",
    "    # 计算每一行的1范数\n",
    "    row_norms = torch.sum(torch.abs(projection_matrix), dim=1)\n",
    "    \n",
    "    # 将每一行的1范数与1的差距作为损失项\n",
    "    norm1_loss = torch.sum(torch.abs(row_norms - 1))  # 总的1范数差异\n",
    "    return norm1_loss\n",
    "\n",
    "# 定义损失函数（最大化方差，最小化协方差）\n",
    "def balanced_variance_loss(x):\n",
    "    # 计算协方差矩阵\n",
    "    x_centered = x - torch.mean(x, dim=0)  # 去均值\n",
    "    cov_matrix = torch.matmul(x_centered.T, x_centered) / (x_centered.shape[0] - 1)  # 协方差矩阵\n",
    "    \n",
    "    # 对协方差矩阵进行特征值分解\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # 目标是使特征值相近，特征值的方差最小化\n",
    "    variance_loss = torch.var(eigenvalues)  # 特征值的方差\n",
    "    \n",
    "    # 计算协方差矩阵的非对角元素的和，目标是使协方差尽可能小\n",
    "    off_diagonal_cov = cov_matrix - torch.diag(torch.diagonal(cov_matrix))  # 非对角元素\n",
    "    covariance_loss = torch.sum(torch.abs(off_diagonal_cov))  # 协方差的绝对和\n",
    "    \n",
    "    # 总损失函数：方差最小化 + 协方差最小化\n",
    "    total_loss = variance_loss + covariance_loss+norm1_constraint()\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# 假设 locations 是你的低维坐标数据，大小为 (n_samples, input_dim)\n",
    "locations = torch.tensor(locations, dtype=torch.float32)\n",
    "\n",
    "# 创建模型\n",
    "model = ProjectionModel(input_dim=locations.shape[1], output_dim=10)  # 将数据升到10维空间\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# 训练过程\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 将数据投影到新的高维空间\n",
    "    projected_locations = model(locations)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = balanced_variance_loss(projected_locations)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# 最终的投影矩阵\n",
    "final_projection_matrix = model.projection_matrix.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FSTimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\connector.py:1116\u001b[0m, in \u001b[0;36mTCPConnector._wrap_create_connection\u001b[1;34m(self, addr_infos, req, timeout, client_error, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1109\u001b[0m         sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m aiohappyeyeballs\u001b[38;5;241m.\u001b[39mstart_connection(\n\u001b[0;32m   1110\u001b[0m             addr_infos\u001b[38;5;241m=\u001b[39maddr_infos,\n\u001b[0;32m   1111\u001b[0m             local_addr_infos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_addr_infos,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1114\u001b[0m             loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop,\n\u001b[0;32m   1115\u001b[0m         )\n\u001b[1;32m-> 1116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_connection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, sock\u001b[38;5;241m=\u001b[39msock)\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m cert_errors \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\asyncio\\base_events.py:1050\u001b[0m, in \u001b[0;36mBaseEventLoop.create_connection\u001b[1;34m(self, protocol_factory, host, port, ssl, family, proto, flags, sock, local_addr, server_hostname, ssl_handshake_timeout, happy_eyeballs_delay, interleave)\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1048\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA Stream Socket was expected, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msock\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1050\u001b[0m transport, protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_transport(\n\u001b[0;32m   1051\u001b[0m     sock, protocol_factory, ssl, server_hostname,\n\u001b[0;32m   1052\u001b[0m     ssl_handshake_timeout\u001b[38;5;241m=\u001b[39mssl_handshake_timeout)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug:\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;66;03m# Get the socket from the transport because SSL transport closes\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# the old socket and creates a new SSL socket\u001b[39;00m\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\asyncio\\base_events.py:1080\u001b[0m, in \u001b[0;36mBaseEventLoop._create_connection_transport\u001b[1;34m(self, sock, protocol_factory, ssl, server_hostname, server_side, ssl_handshake_timeout)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1080\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\client.py:663\u001b[0m, in \u001b[0;36mClientSession._request\u001b[1;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connector\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m    664\u001b[0m         req, traces\u001b[38;5;241m=\u001b[39mtraces, timeout\u001b[38;5;241m=\u001b[39mreal_timeout\n\u001b[0;32m    665\u001b[0m     )\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\connector.py:538\u001b[0m, in \u001b[0;36mBaseConnector.connect\u001b[1;34m(self, req, traces, timeout)\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m trace\u001b[38;5;241m.\u001b[39msend_connection_create_start()\n\u001b[1;32m--> 538\u001b[0m proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(req, traces, timeout)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m traces:\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\connector.py:1050\u001b[0m, in \u001b[0;36mTCPConnector._create_connection\u001b[1;34m(self, req, traces, timeout)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1050\u001b[0m     _, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_direct_connection(req, traces, timeout)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proto\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\connector.py:1384\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[1;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m last_exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1384\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m last_exc\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\connector.py:1353\u001b[0m, in \u001b[0;36mTCPConnector._create_direct_connection\u001b[1;34m(self, req, traces, timeout, client_error)\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1353\u001b[0m     transp, proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_create_connection(\n\u001b[0;32m   1354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_factory,\n\u001b[0;32m   1355\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1356\u001b[0m         ssl\u001b[38;5;241m=\u001b[39msslcontext,\n\u001b[0;32m   1357\u001b[0m         addr_infos\u001b[38;5;241m=\u001b[39maddr_infos,\n\u001b[0;32m   1358\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m   1359\u001b[0m         req\u001b[38;5;241m=\u001b[39mreq,\n\u001b[0;32m   1360\u001b[0m         client_error\u001b[38;5;241m=\u001b[39mclient_error,\n\u001b[0;32m   1361\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ClientConnectorError, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\connector.py:1116\u001b[0m, in \u001b[0;36mTCPConnector._wrap_create_connection\u001b[1;34m(self, addr_infos, req, timeout, client_error, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1109\u001b[0m         sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m aiohappyeyeballs\u001b[38;5;241m.\u001b[39mstart_connection(\n\u001b[0;32m   1110\u001b[0m             addr_infos\u001b[38;5;241m=\u001b[39maddr_infos,\n\u001b[0;32m   1111\u001b[0m             local_addr_infos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_addr_infos,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1114\u001b[0m             loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop,\n\u001b[0;32m   1115\u001b[0m         )\n\u001b[1;32m-> 1116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_connection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, sock\u001b[38;5;241m=\u001b[39msock)\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m cert_errors \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\async_timeout\\__init__.py:179\u001b[0m, in \u001b[0;36mTimeout.__aexit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aexit__\u001b[39m(\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    175\u001b[0m     exc_type: Optional[Type[\u001b[38;5;167;01mBaseException\u001b[39;00m]],\n\u001b[0;32m    176\u001b[0m     exc_val: Optional[\u001b[38;5;167;01mBaseException\u001b[39;00m],\n\u001b[0;32m    177\u001b[0m     exc_tb: Optional[TracebackType],\n\u001b[0;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_exit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\async_timeout\\__init__.py:265\u001b[0m, in \u001b[0;36mTimeout._do_exit\u001b[1;34m(self, exc_type)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# timeout has not expired\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectionTimeoutError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\fsspec\\asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[1;34m(event, coro, result, timeout)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\fsspec\\implementations\\http.py:516\u001b[0m, in \u001b[0;36mHTTPFileSystem._isdir\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ls(path))\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\fsspec\\implementations\\http.py:207\u001b[0m, in \u001b[0;36mHTTPFileSystem._ls\u001b[1;34m(self, url, detail, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ls_real(url, detail\u001b[38;5;241m=\u001b[39mdetail, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdircache[url] \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\fsspec\\implementations\\http.py:159\u001b[0m, in \u001b[0;36mHTTPFileSystem._ls_real\u001b[1;34m(self, url, detail, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_session()\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_url(url), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m r:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_not_found_for_status(r, url)\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\client.py:1360\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[1;32m-> 1360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp: _RetType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[0;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__aenter__\u001b[39m()\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\aiohttp\\client.py:667\u001b[0m, in \u001b[0;36mClientSession._request\u001b[1;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionTimeoutError(\n\u001b[0;32m    668\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection timeout to host \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    669\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mtransport \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mConnectionTimeoutError\u001b[0m: Connection timeout to host https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFSTimeoutError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# 加载数据 (Cora 数据集)\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPlanetoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/Cora\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCora\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# 一个图数据\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# 模型、优化器\u001b[39;00m\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\torch_geometric\\datasets\\planetoid.py:102\u001b[0m, in \u001b[0;36mPlanetoid.__init__\u001b[1;34m(self, root, name, split, num_train_per_class, num_val, num_test, transform, pre_transform, force_reload)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m=\u001b[39m split\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeom-gcn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:81\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     74\u001b[0m     root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     force_reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data: Optional[BaseData] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\torch_geometric\\data\\dataset.py:112\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_reload \u001b[38;5;241m=\u001b[39m force_reload\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_download:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process()\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\torch_geometric\\data\\dataset.py:229\u001b[0m, in \u001b[0;36mDataset._download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    228\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\torch_geometric\\datasets\\planetoid.py:154\u001b[0m, in \u001b[0;36mPlanetoid.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_file_names:\n\u001b[1;32m--> 154\u001b[0m         \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeom-gcn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\torch_geometric\\io\\fs.py:114\u001b[0m, in \u001b[0;36mcp\u001b[1;34m(path1, path2, extract, log, use_cache, clear_cache)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcp\u001b[39m(\n\u001b[0;32m    105\u001b[0m     path1: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    106\u001b[0m     path2: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m     clear_cache: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    111\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 114\u001b[0m     is_path1_dir \u001b[38;5;241m=\u001b[39m \u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     is_path2_dir \u001b[38;5;241m=\u001b[39m isdir(path2)\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Cache result if the protocol is not local:\u001b[39;00m\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\torch_geometric\\io\\fs.py:62\u001b[0m, in \u001b[0;36misdir\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misdir\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_fs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\fsspec\\asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CODEING\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\fsspec\\asyn.py:101\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m return_result \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# suppress asyncio.TimeoutError, raise FSTimeoutError\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n",
      "\u001b[1;31mFSTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "# -------------------------------\n",
    "# 1. GCN 模型\n",
    "# -------------------------------\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # 第一层卷积\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        # 第二层卷积\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 对比学习任务（无监督）\n",
    "# -------------------------------\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # 计算嵌入相似性\n",
    "        sim = torch.mm(z, z.t())  # 点积相似性\n",
    "        sim /= self.temperature\n",
    "\n",
    "        # 构造正负样本\n",
    "        adj = to_dense_adj(edge_index)[0]  # 稠密邻接矩阵\n",
    "        pos_mask = adj > 0  # 正样本\n",
    "        neg_mask = ~pos_mask  # 负样本\n",
    "\n",
    "        # 对比损失\n",
    "        pos_loss = -torch.log(torch.exp(sim[pos_mask]).sum() / torch.exp(sim).sum())\n",
    "        neg_loss = -torch.log(torch.exp(sim[neg_mask]).sum() / torch.exp(sim).sum())\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "# -------------------------------\n",
    "# 3. 图数据加载与训练\n",
    "# -------------------------------\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# 加载数据 (Cora 数据集)\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')\n",
    "data = dataset[0]  # 一个图数据\n",
    "\n",
    "# 模型、优化器\n",
    "model = GCN(in_channels=data.num_features, hidden_channels=64, out_channels=32)\n",
    "loss_fn = ContrastiveLoss(temperature=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# 训练循环\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    z = model(data.x, data.edge_index)  # 学习到的节点嵌入\n",
    "    loss = loss_fn(z, data.edge_index)  # 计算对比损失\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. 结果：嵌入 z 可用于聚类、可视化等\n",
    "# -------------------------------\n",
    "print(\"Final node embeddings:\", z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Venue Category Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 负采样优化\n",
    "空间融合基本方法：基于流行度采样之上，候选负样本缩小到用户活动范围内，目的是排除活动范围外流行的伪负样本\n",
    "活动范围：用户交互过的地点位置取最大外切矩形\n",
    "分层采样：依据交互次数排行 找到频繁访问区域作为生活区 最少访问区域作为危险区 其余部分作为探索区\n",
    "假设1：用户熟知生活区所有地点，因此没有访问的地点作为负样本\n",
    "假设2：危险区可能是用户真的不感兴趣的区域 也有可能是不方便涉足的区域，可以根据危险区和生活区的距离进行从分段处理控制采样比例 危险区采样比例根据其与生活区距离\n",
    "探索区域：融合类目分布进行采样\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "物品的特征可以这样观察 冷门-流行 丰富-稀有 再加上用户访问次数特征 构建出一个三维空间\n",
    "丰富稀有可以转化成 日常化程度 \n",
    "#### 假设1：相比更日常的地点人们对稀有的地点更感兴趣\n",
    "#### 假设2：用户更多访问的地方可能不是因为感兴趣而是因为日常生活需要\n",
    "#### 假设3：用户的频繁访问点是集中的，用户频繁访问区内的地点用户都熟知，未访问的地点大概率是不感兴趣\n",
    "#### 假设4：用户频繁访问区外的用户的偶尔访问点是集中的，用户偶尔访问区根据与频繁访问区的距离可以感知用户是对这块区域没兴趣还是不方便探索，这个距离是根据整体区域大小裁定的\n",
    "#### 假设5：除了偶尔访问区和频繁访问区，剩下的探索区是很未知的，\n",
    "#### 假设6：根据频繁访问区每个类目 用户访问占区域内总数比例 粗略推断用户对类目的兴趣 把这个权重作用在探索区\n",
    "#### 策略1：根据全体交互item划分出总区域\n",
    "#### 策略2：根据分位数划分出频繁访问item，在划分出频繁访问去地理包络，记录包络中心点位置，包络中未访问的项目直接划分成候选负样本\n",
    "#### 策略3：在频繁访问区地理包络外根据分位数划分出偶尔访问item，得到偶尔访问区地理包络，以中心位置到频繁访问区中心位置距离和总区域斜边两者倒数比来度量相近程度作为偶尔访问区采样权重\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "POI_interaction_matrix,category_interaction_matrix,category_ids_counts=counting4all(dataset,device)\n",
    "\n",
    "reciprocalrarity=reciprocal_rarity(category_ids_counts)\n",
    "exprarity=exp_rarity(category_ids_counts,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 现象1：活跃用户和非活跃用户的交互分布特征相似 大多数访问的地点去的次数很少 只有少数地点去了很多次 这些地点反映用户兴趣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# 假设 interaction_matrix 是给定的张量\n",
    "# Step 1: Identify the most active user (column with max interactions excluding the first row and column)\n",
    "active_user_idx = category_interaction_matrix[1:, 1:].sum(1).argmax()\n",
    "active_user = category_interaction_matrix[active_user_idx+1,:].cpu().numpy()\n",
    "\n",
    "# Step 2: Identify the least active user (column with min interactions excluding the first row and column)\n",
    "inactive_user_idx = category_interaction_matrix[1:, 1:].sum(1).argmin()\n",
    "inactive_user = category_interaction_matrix[inactive_user_idx+1,:].cpu().numpy()\n",
    "\n",
    "# 计算均值\n",
    "mean_interaction = category_interaction_matrix[1:,1:].mean(dtype=torch.float32)\n",
    "ordinary_user_idx = (abs(category_interaction_matrix[1:,1:] - mean_interaction)).argmin()\n",
    "ordinary_user=category_interaction_matrix[ordinary_user_idx+1,:].cpu().numpy()\n",
    "\n",
    "# Step 3: Filter out zeros\n",
    "active_user = active_user[active_user > 0]\n",
    "inactive_user = inactive_user[inactive_user > 0]\n",
    "ordinary_user=ordinary_user[ordinary_user>0]\n",
    "\n",
    "# Step 4: Create DataFrames for Plotly\n",
    "active_df = pd.DataFrame({\"Interactions\": active_user, \"User Type\": \"Active User\"})\n",
    "inactive_df = pd.DataFrame({\"Interactions\": inactive_user, \"User Type\": \"Inactive User\"})\n",
    "ordinary_df= pd.DataFrame({\"Interactions\": ordinary_user, \"User Type\": \"Ordinary User\"})\n",
    "\n",
    "# Combine both for easier plotting\n",
    "combined_df = pd.concat([active_df, inactive_df,ordinary_df])\n",
    "print(active_user.sum(),inactive_user.sum(),ordinary_user.sum())\n",
    "# Step 5: Plot histograms using Plotly\n",
    "\n",
    "fig = px.histogram(\n",
    "    combined_df,\n",
    "    x=\"Interactions\",\n",
    "    color=\"User Type\",\n",
    "    title=(\n",
    "      \"How can users' interests be effectively measured,<br>\"\n",
    "      \"while balancing the trade-off between interest breadth and depth,<br>\"\n",
    "      \"as illustrated by interaction quantities of <br>\"\n",
    "      \"User-Category and Category-POI (user-wise) or User-POI?\"),\n",
    "    labels={\"Interactions\": \"Number of Interactions\", \"User Type\": \"User Type\"},\n",
    "    nbins=100,  # Adjust the number of bins as needed\n",
    ")\n",
    "\n",
    "# Customize the title position and style\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        \"y\": 0.7,  # Adjust vertical position (1.0 is top, 0.0 is bottom)\n",
    "        \"x\": 0.5,   # Adjust horizontal position (0.5 is centered)\n",
    "        \"xanchor\": \"center\",  # Anchor to center\n",
    "        \"yanchor\": \"top\",     # Anchor to top\n",
    "        \"font\": {\"size\": 16},  # Adjust font size\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：如何区分大量的少交互地点进行兴趣度量 实际上访问次数极多的地点不具有参考价值 它们可能是日常所需，不能很好地反映兴趣\n",
    "方案：把地点访问次数转化成类目访问次数 \n",
    "首先把userid-itemid交互序列转化成userid-categoryid交互序列进行归并 这样地分布更加平滑，访问总次数是一样的，只不过把大量只访问一次的地点归并成访问多次的类目。 \n",
    "这样我们就可以区分访问次数极少的地点 \n",
    "\n",
    "基于类目的兴趣度量：\n",
    "假设：偶尔访问类目和频繁访问类目不能反映兴趣\n",
    "定义用户兴趣类目：排除极端访问次数类目后的类目\n",
    "\n",
    "问题：用户对访问次数相同的类目兴趣度一致吗？应该怎么区分？\n",
    "方案：基于类目稀有度的加权，同样的访问次数，用户很可能对更稀有的类目感兴趣，引入类目稀有度矩阵\n",
    "\n",
    "后续模型修改：\n",
    "引入兴趣广度概念：不同用户以同样次数访问同个地点，反映的兴趣度是不同的，应该依赖用户访问总类目数量进行加权度量，得到更合理的用户-地点相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：如何把类目数量权重映射到稀有度上？\n",
    "直接映射：倒数加权，这样的得到的稀有度是突变的 我希望稀有度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "\n",
    "\n",
    "reciprocal_rarity=reciprocalrarity.cpu()\n",
    "exp_rarity=exprarity.cpu()\n",
    "\n",
    "# 创建图表对象\n",
    "fig = go.Figure()\n",
    "\n",
    "# Reciprocal Rarity Histogram\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=reciprocal_rarity[1:],\n",
    "    nbinsx=1000,\n",
    "    name=\"Reciprocal Rarity\",\n",
    "    marker_color=\"skyblue\",\n",
    "    histnorm='probability',\n",
    "    opacity=0.7,\n",
    "    showlegend=True  # 不显示图例\n",
    "))\n",
    "\n",
    "# Log Rarity Histogram\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=exp_rarity[1:],\n",
    "    nbinsx=500,\n",
    "    name=\"Exp Rarity\",\n",
    "    marker_color=\"lightgreen\",\n",
    "    opacity=0.7,\n",
    "    histnorm='probability',\n",
    "    showlegend=True  # 不显示图例\n",
    "))\n",
    "\n",
    "# 计算方差和峰度\n",
    "reciprocal_var = torch.var(reciprocal_rarity[1:])\n",
    "reciprocal_kurt = kurtosis(reciprocal_rarity[1:])\n",
    "exp_var = torch.var(exp_rarity[1:])\n",
    "exp_kurt = kurtosis(exp_rarity[1:])\n",
    "\n",
    "\n",
    "# 添加外部文本框显示方差和峰度\n",
    "fig.add_annotation(\n",
    "    x=0.5,  # x轴位置，控制文本框水平位置\n",
    "    y=1.15,  # y轴位置，调整文本框在图表的外部\n",
    "    text=f\"Reciprocal Rarity\\nVar: {reciprocal_var:.4e}, Kurtosis: {reciprocal_kurt:.4e}\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=12, color=\"black\"),\n",
    "    align=\"center\",\n",
    "    bgcolor=\"white\",\n",
    "    opacity=0.8,\n",
    "    xref=\"paper\",  # 使用 'paper' 坐标系，让文本框不受图表范围限制\n",
    "    yref=\"paper\"   # 使用 'paper' 坐标系，使文本框在图表外\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=0.5,  # x轴位置，控制文本框水平位置\n",
    "    y=1.05,  # y轴位置，调整文本框在图表的外部\n",
    "    text=f\"Exp Rarity\\nVar: {exp_var:.4e}, Kurtosis: {exp_kurt:.4e}\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=12, color=\"black\"),\n",
    "    align=\"center\",\n",
    "    bgcolor=\"white\",\n",
    "    opacity=0.8,\n",
    "    xref=\"paper\",  # 使用 'paper' 坐标系，放置在图表外\n",
    "    yref=\"paper\"   # 使用 'paper' 坐标系，放置在图表外\n",
    ")\n",
    "\n",
    "# 更新布局\n",
    "fig.update_layout(\n",
    "    title=\"Histograms of Reciprocal and Log Rarity\",\n",
    "    xaxis_title=\"Value\",\n",
    "    yaxis_title=\"Frequency\",\n",
    "    title_font_size=20,\n",
    "    barmode=\"overlay\",  # 使用 \"overlay\" 叠加直方图，\"group\" 可并排显示\n",
    "    showlegend=True    # 隐藏图例\n",
    ")\n",
    "\n",
    "# 显示图表\n",
    "fig.show()#5.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 2. 将数据转为 PyTorch Tensor 并移动到 GPU 上\n",
    "venue_id = torch.tensor(venue_id, dtype=torch.long).cuda()  \n",
    "venue_category = torch.tensor(venue_category, dtype=torch.long).cuda()\n",
    "x = torch.tensor(x, dtype=torch.float32).cuda()  \n",
    "y = torch.tensor(y, dtype=torch.float32).cuda()\n",
    "\n",
    "# 3. 设置网格的尺寸（例如：每个网格大小为500x500）\n",
    "grid_width = 500  # 网格宽度\n",
    "grid_height = 500  # 网格高度\n",
    "\n",
    "# 4. 计算网格的数量（基于坐标的最大最小值）\n",
    "x_min, x_max = x.min(), x.max()\n",
    "y_min, y_max = y.min(), y.max()\n",
    "\n",
    "# 计算网格行列数\n",
    "num_x_grids = int((x_max - x_min) // grid_width) + 1\n",
    "num_y_grids = int((y_max - y_min) // grid_height) + 1\n",
    "\n",
    "\n",
    "# 5. 分批次处理\n",
    "batch_size = 10000  # 每批处理的样本数量\n",
    "num_batches = len(venue_id) // batch_size + 1  # 批次数量\n",
    "\n",
    "# 创建稠密张量来暂存更新，最后将其转换为稀疏张量\n",
    "venue_density_matrix = torch.zeros((num_y_grids, num_x_grids), dtype=torch.int32).cuda()\n",
    "category_density_matrix = torch.zeros((num_y_grids, num_x_grids, len(torch.unique(venue_category))), dtype=torch.int32).cuda()\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    # 计算每个批次的索引范围\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min((batch_idx + 1) * batch_size, len(venue_id))\n",
    "    \n",
    "    # 获取当前批次数据\n",
    "    batch_venue_id = venue_id[start_idx:end_idx]\n",
    "    batch_venue_category = venue_category[start_idx:end_idx]\n",
    "    batch_x = x[start_idx:end_idx]\n",
    "    batch_y = y[start_idx:end_idx]\n",
    "\n",
    "    # 计算每个数据点所属的网格\n",
    "    grid_x = ((batch_x - x_min) / grid_width).floor().long()  # 计算 x 对应的网格位置\n",
    "    grid_y = ((batch_y - y_min) / grid_height).floor().long()  # 计算 y 对应的网格位置\n",
    "\n",
    "    # 确保网格索引不超出边界\n",
    "    grid_x = torch.clamp(grid_x, 0, num_x_grids - 1)\n",
    "    grid_y = torch.clamp(grid_y, 0, num_y_grids - 1)\n",
    "\n",
    "    # 使用 scatter_add_ 更新稠密张量的计数\n",
    "    venue_density_matrix.index_put_((grid_y, grid_x), torch.ones(len(grid_y), dtype=torch.int32).cuda(), accumulate=True)\n",
    "    \n",
    "    # 更新类别密度矩阵\n",
    "    for i in range(len(batch_venue_category)):\n",
    "        category_density_matrix[grid_y[i], grid_x[i], batch_venue_category[i]] += 1\n",
    "\n",
    "# 7. 将稠密张量转换为稀疏张量\n",
    "venue_density_matrix_sparse = venue_density_matrix.to_sparse()\n",
    "category_density_matrix_sparse = category_density_matrix.to_sparse()\n",
    "\n",
    "# 8. 打印结果\n",
    "print(\"Venue Density Matrix Sparse:\")\n",
    "print(venue_density_matrix_sparse)\n",
    "print(\"Category Density Matrix Sparse:\")\n",
    "print(category_density_matrix_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.colors as pc\n",
    "import torch\n",
    "\n",
    "# 假设 venue_density_matrix_sparse 是一个 PyTorch tensor\n",
    "# 你可以根据你实际的场景替换这个变量\n",
    "venue_density_matrix_sparse = torch.rand(num_y_grids, num_x_grids)  # 模拟密度矩阵\n",
    "\n",
    "# 将 x_min 和 y_min 移回 CPU\n",
    "xmin = x_min.cpu().item()\n",
    "ymin = y_min.cpu().item()\n",
    "\n",
    "# 创建空的图形对象\n",
    "fig = go.Figure()\n",
    "\n",
    "# 定义颜色范围，这里选择一个颜色调色板，如蓝色渐变\n",
    "color_scale = 'Blues'  # 可以选择其他颜色范围，如 'Viridis', 'Cividis', 'Inferno'\n",
    "\n",
    "# 使用 PyTorch 的 max 和 min 函数\n",
    "max_density = torch.max(venue_density_matrix_sparse).item()  # 获取最大密度\n",
    "min_density = torch.min(venue_density_matrix_sparse).item()  # 获取最小密度\n",
    "normalized_density = (venue_density_matrix_sparse - min_density) / (max_density - min_density)  # 归一化\n",
    "\n",
    "# 添加网格图层：根据密度值使用颜色\n",
    "for i in range(num_y_grids):\n",
    "    for j in range(num_x_grids):\n",
    "        # 计算网格的边界\n",
    "        grid_x_min = xmin + j * grid_width\n",
    "        grid_x_max = grid_x_min + grid_width\n",
    "        grid_y_min = ymin + i * grid_height\n",
    "        grid_y_max = grid_y_min + grid_height\n",
    "        \n",
    "        # 根据网格的密度值计算颜色\n",
    "        density = normalized_density[i, j].item()  # 转换为 Python 数字\n",
    "        # 使用颜色渐变进行映射\n",
    "        fillcolor = pc.sequential.Blues[int(density * (len(pc.sequential.Blues) - 1))]\n",
    "\n",
    "        # 绘制矩形网格，设置透明度\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[grid_x_min, grid_x_min, grid_x_max, grid_x_max, grid_x_min],\n",
    "            y=[grid_y_min, grid_y_max, grid_y_max, grid_y_min, grid_y_min],\n",
    "            fill='toself',\n",
    "            fillcolor=fillcolor,\n",
    "            line=dict(width=1, color='black'),  # 添加黑色网格线\n",
    "            mode='lines',\n",
    "            name='Grid',  # 给网格设置名字，用于筛选\n",
    "            visible=True  # 默认显示\n",
    "        ))\n",
    "\n",
    "# 创建一个调色板来表示 category_id 的颜色\n",
    "category_colors = pc.qualitative.Set1\n",
    "marker_colors = [category_colors[c % len(category_colors)] for c in venue_category.cpu().numpy()]\n",
    "\n",
    "# 添加数据点图层\n",
    "fig.add_trace(go.Scattergl(\n",
    "    x=x.cpu().numpy(),\n",
    "    y=y.cpu().numpy(),\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=marker_colors,  # 使用 category_id 作为颜色\n",
    "        showscale=True  # 显示颜色条\n",
    "    ),\n",
    "    name='Data Points',  # 给数据点设置名字，用于筛选\n",
    "    visible=True  # 默认显示\n",
    "))\n",
    "\n",
    "# 设置布局\n",
    "fig.update_layout(\n",
    "    title=\"Venue Points with Density-based Coloring and Grid Lines\",\n",
    "    xaxis_title=\"Longitude\",\n",
    "    yaxis_title=\"Latitude\",\n",
    "    showlegend=True,\n",
    "    updatemenus=[\n",
    "        {\n",
    "            'buttons': [\n",
    "                {\n",
    "                    'args': [None, {'visible': [True, False]}],  # 隐藏数据点，只显示网格\n",
    "                    'label': 'Show Grid Only',\n",
    "                    'method': 'relayout'\n",
    "                },\n",
    "                {\n",
    "                    'args': [None, {'visible': [False, True]}],  # 隐藏网格，只显示数据点\n",
    "                    'label': 'Show Data Points Only',\n",
    "                    'method': 'relayout'\n",
    "                },\n",
    "                {\n",
    "                    'args': [None, {'visible': [True, True]}],  # 显示所有\n",
    "                    'label': 'Show Both',\n",
    "                    'method': 'relayout'\n",
    "                }\n",
    "            ],\n",
    "            'direction': 'down',\n",
    "            'showactive': True,\n",
    "            'x': 0.17,\n",
    "            'xanchor': 'left',\n",
    "            'y': 1.15,\n",
    "            'yanchor': 'top'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 在浏览器中显示\n",
    "fig.show(renderer=\"browser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "地点：偏远中心稀有丰富\n",
    "街区：偏远中心密集稀疏\n",
    "用500m*500m作为基本地理块进行聚合\n",
    "街区密度阈值 街区偏远度阈值\n",
    "中心和密集相关\n",
    "丰富地点一定是便利店之类的常用地点\n",
    "重点是稀有地点区分\n",
    "偏远但密集的是乡镇 偏远密集街区的丰富地点是便民设施 稀有地点大概率是学校 政府等大场地 小概率是景点\n",
    "偏远稀疏的是无人区 偏远稀疏街区的丰富地点可能就是便利店 但是稀有地点很可能是景点\n",
    "中心稀疏是城郊 景点的概率较大\n",
    "中心密集的是市中心 这是推荐的重点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.item_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "# dataset splitting\n",
    "train_data,_,_ = data_preparation(config, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.inter_feat)\n",
    "for batch_idx, interaction in enumerate(train_data):\n",
    "    print(interaction)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import mamba4poi\n",
    "import utils\n",
    "importlib.reload(mamba4poi)\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "from mamba4poi import Mamba4POI\n",
    "import os\n",
    "# 设置 CUDA_LAUNCH_BLOCKING 为 1\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "if __name__ == '__main__':\n",
    "    config = Config(model=Mamba4POI, config_file_list=['config.yaml'])\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    \n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "    logger.info(sys.argv)\n",
    "    logger.info(config)\n",
    "\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    init_seed(config[\"seed\"] + config[\"local_rank\"], config[\"reproducibility\"])\n",
    "    model = Mamba4POI(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "    \n",
    "    transform = construct_transform(config)\n",
    "    flops = get_flops(model, dataset, config[\"device\"], logger, transform)\n",
    "    logger.info(set_color(\"FLOPs\", \"blue\") + f\": {flops}\")\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = Trainer(config, model)\n",
    "\n",
    "    best_valid_score, best_valid_result = trainer.fit(\n",
    "    train_data,\n",
    "    valid_data,  # 可以保留验证数据集\n",
    "    verbose=True,    # 保留详细信息，打印结果\n",
    "    saved=True,      # 根据需要决定是否保存模型参数\n",
    "    show_progress=True,  # 不显示进度条\n",
    "    callback_fn=None  # 如果不需要回调函数，可以设置为 None\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(\n",
    "        test_data, show_progress=config[\"show_progress\"]\n",
    "    )\n",
    "    \n",
    "    environment_tb = get_environment(config)\n",
    "    logger.info(\n",
    "        \"The running environment of this training is as follows:\\n\"\n",
    "        + environment_tb.draw()\n",
    "    )\n",
    "\n",
    "    logger.info(set_color(\"best valid \", \"yellow\") + f\": {best_valid_result}\")\n",
    "    logger.info(set_color(\"test result\", \"yellow\") + f\": {test_result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
